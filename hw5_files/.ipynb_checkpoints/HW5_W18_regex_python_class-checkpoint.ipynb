{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5 - Regex, Python, Classifiers\n",
    "\n",
    "There are three problems in this assignment.\n",
    "\n",
    "1. Text file processing with Python and regex\n",
    "1. Basic EDA with pandas and matplotlib\n",
    "1. Building classifier models with R and/or Python\n",
    "\n",
    "The first two problems use data on YouTube statistics related to top trending videos. The third uses different data.\n",
    "\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "* For Problem 1 you'll end up with one Python script file (.py). If you insist, you could write your function in this notebook but I recommend using PyCharm. You'll also end up with an output csv file that you'll turn in.\n",
    "* This notebook containing your work for the Problems 2. Make sure that you've run all of your cells but that you've also organized your files so that if I have to rerun something, it will all work.\n",
    "* Whatever files you create for Problem 3.\n",
    "\n",
    "Please organize your deliverables within a folder in some coherent way. Include a README.md file to tell me where to find your work and how to test it (mostly for Problem 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - Text file processing with Python\n",
    "\n",
    "See https://www.kaggle.com/datasnaek/youtube-new for a description of this dataset. I've\n",
    "provided the file `USvideos.csv` in the `data` folder.\n",
    "\n",
    "Now you are going to write a short Python script to read the\n",
    "`USvideos.csv` file and do some basic text file manipulation.\n",
    "\n",
    "I'm giving you some skeleton code that you are free to use if you wish. The\n",
    "skeleton code file is called `process_youtube_stats_skeleton.py`. **I highly\n",
    "encourage you to use it as it lays out the steps needed and has many useful\n",
    "code snippets and comments.**\n",
    "\n",
    "You should also review the process_apache_log.py file that\n",
    "we first saw in the Downloads for the regex session - I've included that as well. You can use\n",
    "these files as a starting point for ideas or even just edit and add/delete code\n",
    "as needed to accomplish this last task. Your new Python file should be named:\n",
    "\n",
    "    process_youtube_stats_yourname.py # Obviously replacing \"yourname\" appropriately\n",
    "\n",
    "Your job is to modify the skeleton file (or create a new program\n",
    "from scratch) to accomplish the following. \n",
    "\n",
    "### The big picture\n",
    "The big picture is that you are going to read the file,\n",
    "use regex to find lines having a certain category_id value and some values on \n",
    "that line, update some counters, and write out the lines of interest to a new file.\n",
    "\n",
    "I highly recommend you check out the Kaggle site for this dataset and snoop the data\n",
    "yourself with a text editor.\n",
    "\n",
    "**You must use regex for any text pattern matching.**\n",
    "\n",
    "### The more detailed picture\n",
    "\n",
    "Here are the detailed requirements:\n",
    "\n",
    "* Your function `def` should look like the following (see the skeleton code):\n",
    "\n",
    "      `def process_youtube(fn_youtube , fn_out):`\n",
    "\n",
    "Your function will take an input filename and an output filename as arguments.\n",
    "\n",
    "* You need to loop over the lines in the input file and use regex to determine if each\n",
    "line has a value of 28 for the category_id field. Yes, you can hard code the \n",
    "28 into your regex pattern. Category_id 28 is Science & Technology.\n",
    "\n",
    "For those lines that ARE from category 28:\n",
    "\n",
    "* Increment a counter representing the number of lines matched.\n",
    "* Using the captured trending_date as a dictionary key, update the dictionary\n",
    "of counts by trending_date\n",
    "* Store the line in a master list so that we can write out these lines at the end.\n",
    "\n",
    "For those lines that ARE NOT from category 28:\n",
    "\n",
    "* Increment a counter representing the number of lines NOT matched.\n",
    "\n",
    "After all lines processed,\n",
    "write out a message with the totals. Here's the last few lines of my output.\n",
    "\n",
    "    18.01.01:\t   10 videos\n",
    "    18.26.02:\t    9 videos\n",
    "    18.05.02:\t   14 videos\n",
    "    18.08.01:\t   11 videos\n",
    "    17.22.12:\t    8 videos\n",
    "\n",
    "    Num lines matched --> 1233\n",
    "    Num lines not matched --> 26089\n",
    " \n",
    "    \n",
    "Remember that dictionaries are not sorted and so you're output of the counts by date\n",
    "may differ in the order printed out from mine.\n",
    "\n",
    "Finally, write out the matched lines that you stored in a list.\n",
    "There are several ways to write out a list of strings to a file. Google and\n",
    "StackOverflow are your friend.\n",
    "\n",
    "Again, see the skeleton code.\n",
    "\n",
    "\n",
    "**HACKER EXTRA:** \n",
    "\n",
    "To make this program even better, change the function so that you can pass in\n",
    "any category_id to use as the filter instead of having 28 hard coded in as it is now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - EDA with pandas and plotting libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read in the data\n",
    "Looks like there are two datetime related fields. Let's see if pandas can parse them\n",
    "correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "USvideos = pd.read_csv('data/USvideos.csv', parse_dates=['trending_date', 'publish_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check out the structure of the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** Which of the date fields gets read in correctly as some sort of date or datetime field?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** List the first 10 rows, rows 1500 through 1510, and the last 10 rows of the data frame. Use three separate code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Data cleaning and prep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3**\n",
    "\n",
    "Convert the `trending_date` field to an actual datetime data type using the `to_datetime()` function. Show that it worked with the `.info()` method for data frames. Then compute the difference between `publish_time` and `trending_date` in hours. Store it in a new field called `time_to_trend`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4**\n",
    "\n",
    "Create new field called the `like_ratio` that is the number of likes divided by the sum of the number of likes and dislikes. Then use then use the `describe()` method to get a quick statistical summary of this new field. Then create two more new fields:\n",
    "\n",
    "* `comment_intensity` as the ratio of comment_count and views\n",
    "* `thumbs` as the sum of likes and dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Exploratory analysis with pandas\n",
    "\n",
    "Note: Ignore the fact that some videos appear more than once because they trended multiple times on different dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5**\n",
    "\n",
    "How many videos by channel title? Even better, sort in descending order. Here's what I get for the first few results:\n",
    "\n",
    "    channel_title\n",
    "    ESPN                                      114\n",
    "    Vox                                       113\n",
    "    Netflix                                   112\n",
    "    NBA                                       112\n",
    "    First We Feast                            111\n",
    "    The Tonight Show Starring Jimmy Fallon    109\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6**\n",
    "\n",
    "Which channels are in the top 10 and bottom 10 for the mean of the `like_ratio` field we created above. Only consider channels with at least 5 videos in the USvideos DataFrame.\n",
    "\n",
    "Obviously you will end up with several Python statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7**\n",
    "\n",
    "You'll notice that `category_id` is an integer. Not very informative. Thankfully, the Kaggle site included json files which map category id to a category name. Well, kind of. If you look at the json file in the data folder, you'll see that it's got some other stuff in there. However, if you explore some of the kernels in Kaggle, you might run across the following bit of code which creates a simple dictionary with the `category_id` as the key and a category name as the value. Here's the code. Your job is to figure out how it works and put a comment before each line explaining what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a dictionary that maps `category_id` to `category`\n",
    "import json\n",
    "\n",
    "id_to_category = {}\n",
    "\n",
    "with open('./data/US_category_id.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for category in data['items']:\n",
    "        id_to_category[category['id']] = category['snippet']['title']\n",
    "\n",
    "print(id_to_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8**\n",
    "Now figure out how you can use the `id_to_category` dictionary to create a new field in `USvideos` DataFrame called `category_name` containing, of course, the category name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9**\n",
    "Then, use the `describe()` method along with `group_by` (and maybe `unstack()`) to compute summary statistics of the `views` field, grouping by `category_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Basic plotting in Python\n",
    "\n",
    "Feel free to use either matplotlib, pandas or Seaborn (or any combination of) to create the following basic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a histogram of number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a histogram of the log of number of views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot of likes vs views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of boxplots of like_ratio by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HACKER EXTRA - experiment with additional plots that help us understand this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Classification\n",
    "\n",
    "Coming soon... still tidying up some details on the problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
